import streamlit as st
from agent_executor import InniAgent
from prompt_loader import load_prompt_blocks
from user_state import (
    get_user_inputs, set_pdf_summary,
    get_pdf_summary, save_step_result
)
from utils import extract_text_from_pdf, merge_prompt_content
from dsl_to_prompt import convert_dsl_to_prompt
from user_state import init_user_state

init_user_state()

st.set_page_config(page_title="Inni Analyzer MVP", layout="wide")

st.title("ğŸ“Š Inni Analyzer: GPT-4o ê¸°ë°˜ ê±´ì¶• í”„ë¡œì íŠ¸ ë¶„ì„")

# ğŸ“¥ 1. ì‚¬ìš©ì ì…ë ¥ ìˆ˜ì§‘
st.sidebar.header("ğŸ“¥ í”„ë¡œì íŠ¸ ê¸°ë³¸ ì •ë³´ ì…ë ¥")
user_inputs = get_user_inputs()

uploaded_pdf = st.sidebar.file_uploader("ğŸ“ ê³¼ì—…ì§€ì‹œì„œ ë˜ëŠ” ì œì•ˆìš”ì²­ì„œ (PDF)", type=["pdf"])

if uploaded_pdf:
    pdf_text = extract_text_from_pdf(uploaded_pdf)
    set_pdf_summary(pdf_text)
    st.sidebar.success("âœ… PDF ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")

# ğŸ“¦ 2. í”„ë¡¬í”„íŠ¸ ë¸”ë¡ ë¡œë“œ
blocks = load_prompt_blocks()
block_list = list(blocks.values())

# âœ… 3. ë¶„ì„ ë¸”ë¡ ì„ íƒ
selected_blocks = st.sidebar.multiselect(
    "ğŸ” ë¶„ì„í•  ë¸”ëŸ­ë“¤ì„ ì„ íƒí•˜ê³  ìˆœì„œë¥¼ ì¡°ì •í•˜ì„¸ìš”:",
    block_list,
    format_func=lambda b: f"{b['title']}"
)
# ğŸš€ 4. ë¶„ì„ ì‹¤í–‰
if selected_blocks and st.button("ğŸš€ ì„ íƒí•œ ë¸”ëŸ­ë“¤ ë¶„ì„ ì‹¤í–‰"):
    st.session_state.cot_history = []  # ëˆ„ì  ê²°ê³¼ ì´ˆê¸°í™”

    for idx, block in enumerate(selected_blocks):
        step_id = block["id"]
        title = block["title"]

        # ğŸ”— ëˆ„ì ëœ ì´ì „ ë¶„ì„ ë‚´ìš© ì •ë¦¬ (ë¨¼ì €)
        step_context = "\n".join([
            f"[{prev['step']}] {prev['result']}" for prev in st.session_state.cot_history
        ])

        # DSL ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        if "content_dsl" in block:
            prompt_template = convert_dsl_to_prompt(
                dsl_block=block["content_dsl"],
                user_inputs=user_inputs,
                previous_summary=step_context,
                pdf_summary=get_pdf_summary()
            )
        else:
            prompt_template = block["content"]

        st.markdown(f"### ğŸ“˜ Step {idx+1}: {title}")
        st.code(prompt_template, language="markdown")

        # ğŸ§  ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        full_prompt = merge_prompt_content(
            block_prompt=prompt_template,
            user_info=user_inputs,
            pdf_summary=get_pdf_summary(),
            step_context=step_context
        )

        # ğŸ¤– ë¶„ì„ ì‹¤í–‰
        with st.spinner("ğŸ” GPT ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            agent = InniAgent()
            result = agent.run_analysis(full_prompt)

        # âœ… ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥
        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
        st.markdown("### ğŸ” ê²°ê³¼")
        st.markdown(result)

        st.session_state.cot_history.append({
            "step": f"Step {idx+1}",
            "title": title,
            "prompt": full_prompt,
            "result": result
        })
        save_step_result(step_id, result)

    # ğŸ§  ì „ì²´ ë¶„ì„ íë¦„ ìš”ì•½ (Chain-of-Thought)
    if len(st.session_state.cot_history) > 1:
        st.markdown("---")
        st.markdown("### ğŸ§  ì „ì²´ ë¶„ì„ íë¦„ ìš”ì•½ (Chain-of-Thought)")
        for i, h in enumerate(st.session_state.cot_history):
            st.markdown(f"**{i+1}. {h['title']}**")
            st.markdown(f"- ê²°ê³¼ ìš”ì•½: {h['result'][:200]}...")
