# utils_pdf_vector.py 
import chromadb
import fitz  # PyMuPDF
from sentence_transformers import SentenceTransformer
import streamlit as st
import os
from typing import List, Dict, Optional

# pysqlite3 ê´€ë ¨ ì½”ë“œ ì™„ì „ ì œê±°

# 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ê°€ë³ê³  ë¬´ë£Œ)
try:
    st.info("ğŸ”„ ê³ ê¸‰ PDF ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
    st.success("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    st.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    embedder = None

# 2. ChromaDB ì¸ìŠ¤í„´ìŠ¤
try:
    chroma_client = chromadb.Client()
    collection = chroma_client.get_or_create_collection("pdf_chunks")
    st.success("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ")
except Exception as e:
    st.error(f"âŒ ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
    collection = None

def search_pdf_chunks(query: str, pdf_id: str = "default", top_k: int = 3) -> str:
    """ê³ ê¸‰ PDF ë²¡í„° ê²€ìƒ‰ í•¨ìˆ˜ - í˜¸í™˜ì„± ê°œì„ """
    
    if not embedder or not collection:
        st.warning("âš ï¸ ê³ ê¸‰ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨, ê°„ë‹¨ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
        return fallback_to_simple_search(query, pdf_id, top_k)
    
    try:
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        q_embed = embedder.encode([query])[0].tolist()
        
        # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
        result = collection.query(
            query_embeddings=[q_embed], 
            n_results=top_k
        )
        
        # ê²°ê³¼ ì²˜ë¦¬
        if (result and "documents" in result and 
            result["documents"][0] and len(result["documents"][0]) > 0):
            
            chunks = result["documents"][0]
            formatted_chunks = []
            
            for i, chunk in enumerate(chunks, 1):
                # ì²­í¬ ê¸¸ì´ ì œí•œ (ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ í‘œì‹œ)
                if len(chunk) > 500:
                    chunk = chunk[:500] + "..."
                formatted_chunks.append(f"ğŸ“„ ê³ ê¸‰ ê²€ìƒ‰ ê²°ê³¼ {i}:\n{chunk}")
            
            return "\n---\n".join(formatted_chunks)
        else:
            st.info("â„¹ï¸ ê³ ê¸‰ ê²€ìƒ‰ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return "[ê³ ê¸‰ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ]"
            
    except Exception as e:
        st.error(f"âŒ ê³ ê¸‰ PDF ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return fallback_to_simple_search(query, pdf_id, top_k)

def fallback_to_simple_search(query: str, pdf_id: str, top_k: int) -> str:
    """ê³ ê¸‰ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ê°„ë‹¨ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±"""
    try:
        # ê°„ë‹¨ ê²€ìƒ‰ ë¡œì§
        if 'pdf_chunks' not in st.session_state or pdf_id not in st.session_state.pdf_chunks:
            return "[PDFê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.]"
        
        text = st.session_state.pdf_chunks[pdf_id]
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
        import re
        keywords = re.findall(r'\w+', query.lower())
        paragraphs = text.split('\n\n')
        
        scored_paragraphs = []
        for para in paragraphs:
            if len(para.strip()) < 50:
                continue
                
            para_lower = para.lower()
            score = sum(1 for keyword in keywords if keyword in para_lower)
            
            if score > 0:
                scored_paragraphs.append((score, para.strip()))
        
        scored_paragraphs.sort(key=lambda x: x[0], reverse=True)
        
        results = []
        for i, (score, para) in enumerate(scored_paragraphs[:top_k], 1):
            if len(para) > 500:
                para = para[:500] + "..."
            results.append(f"ğŸ“„ ê°„ë‹¨ ê²€ìƒ‰ ê²°ê³¼ {i} (ê´€ë ¨ë„: {score}):\n{para}")
        
        if results:
            return "\n---\n".join(results)
        else:
            return "[ê°„ë‹¨ ê²€ìƒ‰ì—ì„œë„ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤]"
            
    except Exception as e:
        return f"[ê²€ìƒ‰ ì˜¤ë¥˜: {e}]"

def pdf_to_chunks(pdf_path: str, chunk_size: int = 400) -> List[str]:
    """PDFë¥¼ ì²­í¬ë¡œ ë¶„í• """
    
    if not os.path.exists(pdf_path):
        st.error(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return []
    
    try:
        doc = fitz.open(pdf_path)
        all_chunks = []
        
        for page_num, page in enumerate(doc):
            text = page.get_text()
            if not text.strip():
                continue
                
            # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¶„í• 
            paragraphs = text.split('\n\n')
            for para in paragraphs:
                para = para.strip()
                if len(para) < 50:  # ë„ˆë¬´ ì§§ì€ ê²ƒ ì œì™¸
                    continue
                    
                # ì²­í¬ í¬ê¸°ë¡œ ìë¥´ê¸°
                for i in range(0, len(para), chunk_size):
                    chunk = para[i:i+chunk_size].strip()
                    if len(chunk) > 50:
                        all_chunks.append(chunk)
        
        doc.close()
        st.success(f"âœ… PDF ë¶„í•  ì™„ë£Œ: {len(all_chunks)}ê°œ ì²­í¬")
        return all_chunks
        
    except Exception as e:
        st.error(f"âŒ PDF ë¶„í•  ì˜¤ë¥˜: {e}")
        return []

def save_pdf_chunks_to_chroma(pdf_path: str, pdf_id: str = "default") -> bool:
    """PDF ì²­í¬ë¥¼ ChromaDBì— ì €ì¥ - í˜¸í™˜ì„± ê°œì„ """
    
    if not embedder or not collection:
        st.warning("âš ï¸ ê³ ê¸‰ ì €ì¥ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨, ê°„ë‹¨ ì €ì¥ìœ¼ë¡œ ì „í™˜")
        return fallback_to_simple_save(pdf_path, pdf_id)
    
    try:
        # PDF ì²­í¬ ìƒì„±
        chunks = pdf_to_chunks(pdf_path)
        if not chunks:
            st.error("âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # ì„ë² ë”© ìƒì„±
        st.info("ğŸ”„ PDF ë²¡í„°í™” ì¤‘...")
        embeds = embedder.encode(chunks).tolist()
        
        # ê³ ìœ  ID ìƒì„±
        ids = [f"{pdf_id}_{i}" for i in range(len(chunks))]
        
        # ChromaDBì— ì €ì¥
        collection.add(
            ids=ids,
            documents=chunks,
            embeddings=embeds
        )
        
        st.success(f"âœ… ê³ ê¸‰ PDF ë²¡í„° ì €ì¥ ì™„ë£Œ: {pdf_id} ({len(chunks)}ê°œ ì²­í¬)")
        return True
        
    except Exception as e:
        st.error(f"âŒ ê³ ê¸‰ PDF ì €ì¥ ì˜¤ë¥˜: {e}")
        return fallback_to_simple_save(pdf_path, pdf_id)

def fallback_to_simple_save(pdf_path: str, pdf_id: str) -> bool:
    """ê³ ê¸‰ ì €ì¥ ì‹¤íŒ¨ ì‹œ ê°„ë‹¨ ì €ì¥ìœ¼ë¡œ í´ë°±"""
    try:
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = extract_text_from_pdf(pdf_path)
        if not text:
            return False
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        if 'pdf_chunks' not in st.session_state:
            st.session_state.pdf_chunks = {}
        
        st.session_state.pdf_chunks[pdf_id] = text
        st.success(f"âœ… ê°„ë‹¨ PDF í…ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: {len(text)} ë¬¸ì")
        return True
        
    except Exception as e:
        st.error(f"âŒ ê°„ë‹¨ PDF ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def extract_text_from_pdf(pdf_path: str) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í˜¸í™˜ì„±)"""
    try:
        doc = fitz.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        return text
    except Exception as e:
        st.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""

def get_pdf_summary(pdf_id: str = "default") -> str:
    """PDF ìš”ì•½ (í˜¸í™˜ì„±)"""
    try:
        if 'pdf_chunks' not in st.session_state or pdf_id not in st.session_state.pdf_chunks:
            return "[PDFê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤]"
        
        text = st.session_state.pdf_chunks[pdf_id]
        
        if len(text) > 1000:
            summary = text[:1000] + "..."
        else:
            summary = text
        
        return summary
        
    except Exception as e:
        st.error(f"âŒ PDF ìš”ì•½ ì‹¤íŒ¨: {e}")
        return f"[ìš”ì•½ ì˜¤ë¥˜: {e}]"