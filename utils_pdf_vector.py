# utils_pdf_vector.py 
import fitz  # PyMuPDF
import streamlit as st
import os
from typing import List, Dict, Optional

# ë²¡í„° ì‹œìŠ¤í…œ ì™„ì „ ë¹„í™œì„±í™” (ë©”íƒ€ í…ì„œ ì˜¤ë¥˜ ë°©ì§€)
embedder = None
collection = None
chroma_client = None

def initialize_vector_system():
    """ë²¡í„° ì‹œìŠ¤í…œ ì´ˆê¸°í™” - ê°„ë‹¨ ê²€ìƒ‰ë§Œ ì‚¬ìš©"""
    global embedder, collection, chroma_client
    
    # ê³ ê¸‰ ë²¡í„° ì‹œìŠ¤í…œ ì™„ì „ ë¹„í™œì„±í™”
    embedder = None
    collection = None
    chroma_client = None
    
    # ë©”ì‹œì§€ ì œê±° - ì¡°ìš©íˆ True ë°˜í™˜
    return True

def search_pdf_chunks(query: str, pdf_id: str = "default", top_k: int = 3) -> str:
    """PDF ê²€ìƒ‰ í•¨ìˆ˜ - ê°„ë‹¨ ê²€ìƒ‰ë§Œ ì‚¬ìš©"""
    return fallback_to_simple_search(query, pdf_id, top_k)

def save_pdf_chunks_to_chroma(pdf_path: str, pdf_id: str = "default") -> bool:
    """PDF ì²­í¬ë¥¼ ê°„ë‹¨ ì €ì¥ìœ¼ë¡œ ì²˜ë¦¬"""
    try:
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = extract_text_from_pdf(pdf_path)
        
        if not text:
            st.error("âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            return False
        
        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        if 'pdf_chunks' not in st.session_state:
            st.session_state.pdf_chunks = {}
        
        st.session_state.pdf_chunks[pdf_id] = text
        st.success(f"âœ… PDFê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ê°„ë‹¨ ëª¨ë“œ)")
        return True
        
    except Exception as e:
        st.error(f"âŒ PDF ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def fallback_to_simple_search(query: str, pdf_id: str, top_k: int) -> str:
    """ê°„ë‹¨ ê²€ìƒ‰ - í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰"""
    try:
        # PDF í…ìŠ¤íŠ¸ í™•ì¸
        if 'pdf_chunks' not in st.session_state or pdf_id not in st.session_state.pdf_chunks:
            return "[PDFê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.]"
        
        text = st.session_state.pdf_chunks[pdf_id]
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
        import re
        keywords = re.findall(r'\w+', query.lower())
        paragraphs = text.split('\n\n')
        
        scored_paragraphs = []
        for para in paragraphs:
            if len(para.strip()) < 50:
                continue
                
            para_lower = para.lower()
            score = sum(1 for keyword in keywords if keyword in para_lower)
            
            if score > 0:
                scored_paragraphs.append((score, para.strip()))
        
        scored_paragraphs.sort(key=lambda x: x[0], reverse=True)
        
        results = []
        for i, (score, para) in enumerate(scored_paragraphs[:top_k], 1):
            if len(para) > 500:
                para = para[:500] + "..."
            results.append(f"ğŸ“„ ê°„ë‹¨ ê²€ìƒ‰ ê²°ê³¼ {i} (ê´€ë ¨ë„: {score}):\n{para}")
        
        if results:
            return "\n---\n".join(results)
        else:
            return "[ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.]"
            
    except Exception as e:
        st.error(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return "[ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.]"

def pdf_to_chunks(pdf_path: str, chunk_size: int = 400) -> List[str]:
    """PDFë¥¼ ì²­í¬ë¡œ ë¶„í• """
    try:
        doc = fitz.open(pdf_path)
        chunks = []
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            text = page.get_text()
            
            # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
            sentences = text.split('. ')
            
            current_chunk = ""
            for sentence in sentences:
                if len(current_chunk) + len(sentence) < chunk_size:
                    current_chunk += sentence + ". "
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence + ". "
            
            # ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
            if current_chunk:
                chunks.append(current_chunk.strip())
        
        doc.close()
        return chunks
        
    except Exception as e:
        st.error(f"âŒ PDF ì²­í¬ ë¶„í•  ì˜¤ë¥˜: {e}")
        return []

def extract_text_from_pdf(pdf_path: str) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        doc = fitz.open(pdf_path)
        text = ""
        
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            text += page.get_text() + "\n"
        
        doc.close()
        return text
        
    except Exception as e:
        st.error(f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return ""

def get_pdf_summary(pdf_id: str = "default") -> str:
    """PDF ìš”ì•½ ì •ë³´ ë°˜í™˜"""
    if 'pdf_chunks' not in st.session_state or pdf_id not in st.session_state.pdf_chunks:
        return "[PDF ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.]"
    
    text = st.session_state.pdf_chunks[pdf_id]
    return text[:1000] + "..." if len(text) > 1000 else text